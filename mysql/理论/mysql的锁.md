### mysql 中的锁
数据库锁的设计初衷是为了处理并发问题，作为多用户共享的资源，当出现并发问题时，数据库需要合理的控制访问规则。而锁就是实现这些访问规则的重要数据结构。

根据锁的范围，mysql 里面的锁分为 `全局锁`，`表锁`，`行锁`三类.

#### 全局锁
全局锁就是对整个数据库就行加锁。mysql 提供了一个全局读锁的方法，命令是 `flush tables with read lock(FTWRL)`.当你需要整个库处于只读状态的时候，可以使用整个命令，之后其他线程的一下语句会被阻塞：数据更新语句（数据的增删改），数据定义语句（建表，修改表结构）和更新类事务的提交语句。

###### 全局锁的使用场景
做全库逻辑备份。也就是把整个库 select 出来存成文本。
使用全局锁备份库的危害：
1. 如果你在主库上备份，那么在备份期间都不执行更新，业务基本上都的停止。
2. 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟

官方 mysql 提供了 mysqldump，当使用 `mysqldemp --single-transaction` 的时候，导数据之前会启动一个事务，来确保一致性视图。有了 mysqldump 为啥还要使用 `FTWRL`？ 比如，对于 myisam 这种不支持事务的引擎，如果备份过程中有更新，总是能取到最新的数据，那么就破坏了备份的一致性。这是我们就需要使用 `FTWRL` 命令了。

所以 `single-transaction` 只是适用于所有的表使用事务引擎的库。如果有的表使用不支持事务的引擎，那么备份就只能通过 `FTWRL` 方法。

##### 既然要全库只读，使用 `set global readonly=true` 的方式？
为啥不建议使用这个把全库只读原因是
1. 在系统中，`readonly` 的值会被用来做其他逻辑。比如用来判断是`主库还是备库`。修改 global 影响面更大
2. 在异常处理机制上有差别。如果执行 `FTWRL`命令之后由于客户端发送异常断开，myslq 会自动释放这个全局锁，整个库可以回到正常更新状态。而讲整个库设置为 readonly 之后，如果客户端异常，数据库会一直保持 readonly 状态，这会导致整个库长时间处于不可写状态。


#### 表级锁
mysql 的表级锁有两种：`表锁` 和 `元数据锁(meta data lock, MDL)`.

##### 表锁
表锁的语法是 lock tables ... read/write. 与 FTWRL 类似，可以使用 unlock tables 释放锁。也可以在客户端点开的时候自动释放。lock tables 出了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

举个栗子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。


#####  MDL（meta data lock）
`MDL` `不需要显式使用`，在访问一个表的时候会被`自动加上`。MDL 的作用是，保证`读写`的`正确性`。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的

* 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。

* 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

事务中的 MDL 锁，在语句执行`开始时申请`，但是语句结束后并不会马上释放，而会等到整个`事务提交后再释放`

![DML](https://github.com/kareTauren/pratice/blob/master/mysql/%E7%90%86%E8%AE%BA/img/DML.jpg)

我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。

之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。

如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。

如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。

##### 如何安全地给小表加字段？
1. 首先解决长事务，事务不提交，MDL 就会一直占着。在 mysql 的 `information_schema`库的 `innodb_trx`表中，可以查询当前执行中的事务。如果要变更的表有长事务在执行，就需要考虑暂停 DDL，或者 kill 掉这个长事务。
2. 在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。
MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法
```sql
ALTER TABLE tbl_name NOWAIT add column ...
ALTER TABLE tbl_name WAIT N add column ...
```

#### 行级锁
MySQL 的行锁是在引擎层由各个引擎自己实现的,但是不代表所有引擎都支持行锁。比如 MyISAM 就不支持行锁，只支持表锁，那就意味着并发控制只能使用表锁来控制。对于 MyISAM 这种并发控制，同一时间只能有一个更新在执行，这会影响到并发业务控制。InnoDB 是支持行锁的。这也是 Innodb 代替 MyISAM 的一个重要原因。

`行锁` 就是数据表中 `行记录的锁`。比如事务A更新了一行，此时事务B也更新了一行，那么事务B必须等事务A完成了后才可以进行更新。

在 InnoDB 事务中，`行锁` 是在需要的时候才加上的，`但并不是不需要了就立刻释放`，而是要等到 `事务结束` 时才释放。这个就是 `两阶段锁协议`。

> 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放

如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的 MySQL 就挂了。你登上服务器一看，CPU 消耗接近 100%，但整个数据库每秒就执行不到 100 个事务。这是什么原因呢？

##### 死锁和死锁检测
当并发系统中不同线程 `出现循环资源依赖`，涉及的线程都在 `等待别的线程释放资源时`，就会导致这`几个线程都进入无限等待的状态`，称为 `死锁`

![死锁](https://github.com/kareTauren/pratice/blob/master/mysql/%E7%90%86%E8%AE%BA/img/111.jpg)

这时候，事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：

1. 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 `innodb_lock_wait_timeout` 来设置。

2. 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 `on`，表示开启这个逻辑。

如果是我们上面说到的所有事务都要更新同一行的场景呢？

每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务

怎么解决由这种热点行更新导致的性能问题呢？问题的症结在于，死锁检测要耗费大量的 CPU 资源

`一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险`，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。

`另一个思路是控制并发度`。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。

可能你会问，如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？你可以考虑`通过将一行改成逻辑上的多行来减少锁冲突`。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。


