##### 如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在 mysql 执行过程中的那个阶段报出来的呢？

答：本题考查 mysql 的执行过程。要了解 mysql 的执行过程就可以答得此题。首先 mysql 的执行过程是由客户端发起 -> 链接器 -> 缓存 -> 分析器 -> 优化器 -> 执行器 -> engine层。根据问题此答案为：分析器层。

----

##### 定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？

答：一天一备份，最坏情况下，只需要应用一天的 binlog 就可以了。比如，你每天 0 点做一次全量备份，而要恢复出一个到昨天晚上 23 点的备份。一周一备最坏情况就要应用一周的 binlog 了。

----

##### 系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？

答
###### 首先，从应用开发端来看
1. 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 
2. 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。
3. 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间

###### 其次，从数据库端来看
1. 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；
2. Percona 的 pt-kill 这个工具不错，推荐使用；
3. 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；
4. 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。

----

##### 哪一个索引可以删除掉？
表结构如下：
```sql
CREATE TABLE `geek` ( 
`a` int(11) NOT NULL,
`b` int(11) NOT NULL, 
`c` int(11) NOT NULL,
`d` int(11) NOT NULL,
PRIMARY KEY (`a`,`b`),
KEY `c` (`c`), 
KEY `ca` (`c`,`a`),
KEY `cb` (`c`,`b`)
) ENGINE=InnoDB;
```
公司的同事告诉他说，由于历史原因，这个表需要 a、b 做联合主键，这个小吕理解了。

但是，学过本章内容的小吕又纳闷了，既然主键包含了 a、b 这两个字段，那意味着单独在字段 c 上创建一个索引，就已经包含了三个字段了呀，为什么要创建 `ca` `cb` 这两个索引？

同事告诉他，是因为他们的业务里面有这样的两种语句
```sql
select * from geek where c=N order by a limit 1;
select * from geek where c=N order by b limit 1;
```
问题是，这位同事的解释对吗，为了这两个查询模式，这两个索引是否都是必须的？为什么呢？

答：可以删除 `ca`, 因为 a 是主键索引，
当使用 `select * from geek where c=N order by a limit 1;`语句是，先按照 `c`匹配查找，然后按照 `a` 排序，又因为 `a` 是主键，已经是排好序的，所以不需要 `ca`.
为啥不能删除  `cb` 了? 
当使用 `select * from geek where c=N order by b limit 1;` 语句时，会按照 `c` 匹配查找，虽然主键里面有 `ab` 主键，但是这里的排序是先根据 `a`排序，再根据 `b` 排序的，所以当使用到 `order by b` 时，还是需要在排序一次，如果建立了 `cb` 复合主键，就不需要在排序，从而提高了查询效率。


----

##### 如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：
```
第一种，直接执行 `delete from T limit 10000`;
第二种，在一个连接中循环执行 20 次 delete from T limit 500;
第三种，在 20 个连接中同时执行 delete from T limit 500。
```
你会选择哪一种方法呢？为什么呢？

答：第二种。
第一种，单个语句占用时间长，锁的时间也越长；而且大事务还会导致主从延迟

第二种，串行化执行，将相对长的事务分成多次相对短的事务，则每次事务占用锁的时间相对较短，其他客户端在等待相应资源的时间也较短。这样的操作，同时也意味着将资源分片使用（每次执行使用不同片段的资源），可以提高并发性

第三种，会加剧锁竞争，加剧并发量。